{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize these\n",
    "video_dir = 'video/'\n",
    "frame_dir = 'frames/'\n",
    "output_dir = 'result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available input / video file :  ['test.mp4']\n"
     ]
    }
   ],
   "source": [
    "print('Available input / video file : ',os.listdir(video_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected input video file is : test.mp4\n"
     ]
    }
   ],
   "source": [
    "fname = os.listdir(video_dir)[1]\n",
    "print('Selected input video file is :',fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    canny_edge = cv2.Canny(blur, 170, 200)\n",
    "    \n",
    "    (new, contours, _) = cv2.findContours(canny_edge.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours=sorted(contours, key = cv2.contourArea, reverse = True)[:30] \n",
    "    plate_count = None \n",
    "    status = False\n",
    "    \n",
    "    \n",
    "    for c in contours:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:  \n",
    "            plate_count = approx \n",
    "            break\n",
    "    \n",
    "    if isinstance(plate_count,np.ndarray) :\n",
    "        kernel = np.zeros(gray.shape,np.uint8)\n",
    "        num_plt_image = cv2.drawContours(kernel,[plate_count],0,255,-1)\n",
    "        num_plt_image = cv2.bitwise_and(frame,frame,mask=kernel)\n",
    "        status = True\n",
    "    else:\n",
    "        num_plt_image = frame\n",
    "    \n",
    "    th, binary = cv2.threshold( num_plt_image, 127,255,cv2.THRESH_BINARY );\n",
    "# cv2.imwrite('binary.png',binary)\n",
    "    return binary, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2Frame(inDir, outDir, fname):\n",
    "    vidcapture = cv2.VideoCapture(os.path.join(inDir, fname))\n",
    "    success,image = vidcapture.read()\n",
    "    count = 0\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "    while success:\n",
    "        image, stat = preprocess_frame(imutils.rotate(image,-90))\n",
    "        if stat == True:\n",
    "            cv2.imwrite(outDir+\"\\\\frame%d.png\" % count, image)\n",
    "        success,image = vidcapture.read()\n",
    "        count += 1\n",
    "    print('video to frame converted successfully for file: ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video to frame converted successfully for file:  test.mp4\n"
     ]
    }
   ],
   "source": [
    "convert2Frame(video_dir, frame_dir, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    return cv2.dnn.readNet(os.path.join('model','deep_model.pb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_from_image(img_path, model=model):\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    orig_image = image.copy()\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    (newW, newH) = (320, 320)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    image = cv2.resize(image, (320, 320))\n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    \n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    model.setInput(blob)\n",
    "    (scores, geometry) = model.forward(layerNames)\n",
    "    \n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    for y in range(0, numRows):\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        for x in range(0, numCols):\n",
    "            if scoresData[x] < 0.5:\n",
    "                continue\n",
    "\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    count = 0\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "        plate = orig_image[startY:endY, startX:endX]\n",
    "#         img = cv2.rectangle(orig_image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "#         plt.imshow(img)\n",
    "        cv2.imwrite(str(count)+'.png',plate)\n",
    "#         cv2.rectangle(orig_image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        count += 1\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_frame(imgpath):\n",
    "#     image = detect_text_from_image(imgpath)\n",
    "#     plt.imshow(image)\n",
    "    image = cv2.imread(imgpath)\n",
    "    config = ('-l eng --oem 1 --psm 3')\n",
    "    pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "    text = pytesseract.image_to_string(image, config=config)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame0.png', 'frame1.png', 'frame10.png', 'frame100.png', 'frame101.png', 'frame102.png', 'frame103.png', 'frame104.png', 'frame105.png', 'frame106.png', 'frame107.png', 'frame108.png', 'frame109.png', 'frame11.png', 'frame110.png', 'frame111.png', 'frame112.png', 'frame113.png', 'frame114.png', 'frame115.png', 'frame116.png', 'frame117.png', 'frame118.png', 'frame119.png', 'frame12.png', 'frame120.png', 'frame121.png', 'frame122.png', 'frame123.png', 'frame124.png', 'frame125.png', 'frame126.png', 'frame127.png', 'frame128.png', 'frame129.png', 'frame13.png', 'frame130.png', 'frame131.png', 'frame132.png', 'frame133.png', 'frame134.png', 'frame135.png', 'frame136.png', 'frame137.png', 'frame138.png', 'frame139.png', 'frame14.png', 'frame140.png', 'frame141.png', 'frame142.png', 'frame143.png', 'frame144.png', 'frame145.png', 'frame146.png', 'frame147.png', 'frame148.png', 'frame149.png', 'frame15.png', 'frame150.png', 'frame151.png', 'frame152.png', 'frame153.png', 'frame154.png', 'frame155.png', 'frame156.png', 'frame157.png', 'frame158.png', 'frame159.png', 'frame16.png', 'frame160.png', 'frame161.png', 'frame162.png', 'frame163.png', 'frame164.png', 'frame165.png', 'frame166.png', 'frame167.png', 'frame168.png', 'frame169.png', 'frame17.png', 'frame170.png', 'frame171.png', 'frame172.png', 'frame173.png', 'frame174.png', 'frame175.png', 'frame176.png', 'frame177.png', 'frame178.png', 'frame179.png', 'frame18.png', 'frame180.png', 'frame182.png', 'frame183.png', 'frame184.png', 'frame185.png', 'frame186.png', 'frame188.png', 'frame189.png', 'frame19.png', 'frame190.png', 'frame191.png', 'frame192.png', 'frame193.png', 'frame195.png', 'frame197.png', 'frame198.png', 'frame199.png', 'frame2.png', 'frame20.png', 'frame200.png', 'frame202.png', 'frame203.png', 'frame204.png', 'frame206.png', 'frame207.png', 'frame208.png', 'frame209.png', 'frame21.png', 'frame210.png', 'frame211.png', 'frame213.png', 'frame215.png', 'frame22.png', 'frame222.png', 'frame223.png', 'frame225.png', 'frame227.png', 'frame228.png', 'frame229.png', 'frame23.png', 'frame230.png', 'frame231.png', 'frame232.png', 'frame233.png', 'frame234.png', 'frame235.png', 'frame236.png', 'frame237.png', 'frame238.png', 'frame239.png', 'frame24.png', 'frame240.png', 'frame242.png', 'frame243.png', 'frame244.png', 'frame245.png', 'frame246.png', 'frame247.png', 'frame248.png', 'frame25.png', 'frame250.png', 'frame251.png', 'frame252.png', 'frame253.png', 'frame256.png', 'frame257.png', 'frame258.png', 'frame259.png', 'frame26.png', 'frame260.png', 'frame261.png', 'frame262.png', 'frame264.png', 'frame265.png', 'frame266.png', 'frame267.png', 'frame268.png', 'frame269.png', 'frame27.png', 'frame270.png', 'frame271.png', 'frame272.png', 'frame273.png', 'frame274.png', 'frame275.png', 'frame276.png', 'frame277.png', 'frame278.png', 'frame279.png', 'frame28.png', 'frame281.png', 'frame282.png', 'frame283.png', 'frame284.png', 'frame285.png', 'frame286.png', 'frame287.png', 'frame288.png', 'frame289.png', 'frame29.png', 'frame290.png', 'frame291.png', 'frame292.png', 'frame293.png', 'frame294.png', 'frame295.png', 'frame296.png', 'frame297.png', 'frame298.png', 'frame299.png', 'frame3.png', 'frame30.png', 'frame302.png', 'frame303.png', 'frame304.png', 'frame305.png', 'frame308.png', 'frame309.png', 'frame31.png', 'frame310.png', 'frame311.png', 'frame312.png', 'frame313.png', 'frame314.png', 'frame315.png', 'frame316.png', 'frame317.png', 'frame318.png', 'frame32.png', 'frame320.png', 'frame322.png', 'frame324.png', 'frame325.png', 'frame327.png', 'frame328.png', 'frame329.png', 'frame33.png', 'frame330.png', 'frame331.png', 'frame332.png', 'frame333.png', 'frame334.png', 'frame336.png', 'frame337.png', 'frame338.png', 'frame34.png', 'frame341.png', 'frame342.png', 'frame343.png', 'frame344.png', 'frame347.png', 'frame348.png', 'frame35.png', 'frame350.png', 'frame351.png', 'frame352.png', 'frame353.png', 'frame357.png', 'frame36.png', 'frame362.png', 'frame363.png', 'frame364.png', 'frame367.png', 'frame37.png', 'frame38.png', 'frame39.png', 'frame4.png', 'frame40.png', 'frame41.png', 'frame42.png', 'frame43.png', 'frame44.png', 'frame45.png', 'frame46.png', 'frame47.png', 'frame48.png', 'frame49.png', 'frame5.png', 'frame50.png', 'frame51.png', 'frame52.png', 'frame53.png', 'frame54.png', 'frame55.png', 'frame56.png', 'frame57.png', 'frame58.png', 'frame59.png', 'frame6.png', 'frame60.png', 'frame61.png', 'frame62.png', 'frame63.png', 'frame64.png', 'frame65.png', 'frame66.png', 'frame67.png', 'frame68.png', 'frame69.png', 'frame7.png', 'frame70.png', 'frame71.png', 'frame72.png', 'frame73.png', 'frame74.png', 'frame75.png', 'frame76.png', 'frame77.png', 'frame78.png', 'frame79.png', 'frame8.png', 'frame80.png', 'frame81.png', 'frame82.png', 'frame83.png', 'frame84.png', 'frame85.png', 'frame86.png', 'frame87.png', 'frame88.png', 'frame89.png', 'frame90.png', 'frame91.png', 'frame92.png', 'frame93.png', 'frame94.png', 'frame95.png', 'frame96.png', 'frame97.png', 'frame98.png', 'frame99.png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(frame_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_from_frame('frames/frame330.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
